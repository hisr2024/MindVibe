/**
 * Elite Neural TTS Service
 *
 * Hybrid online/offline Text-to-Speech with:
 * - SSML support for natural speech
 * - Emotional prosody (compassionate, encouraging, meditative)
 * - Automatic voice selection based on context
 * - Streaming audio support for low latency
 *
 * Siri/Alexa-class voice quality.
 */

// TTS Configuration
export interface TTSConfig {
  mode: 'online' | 'offline' | 'auto'
  voicePersona: 'calm' | 'wisdom' | 'friendly'
  language: string
  speechRate: number
  pitch: number
  emotionalTone: 'compassionate' | 'encouraging' | 'meditative'
  volume: number
}

// Voice selection options
export interface VoiceOption {
  name: string
  lang: string
  gender: 'male' | 'female' | 'neutral'
  quality: 'standard' | 'neural' | 'wavenet'
  localService: boolean
}

// Speech event callbacks
export interface TTSCallbacks {
  onStart?: () => void
  onEnd?: () => void
  onPause?: () => void
  onResume?: () => void
  onProgress?: (charIndex: number, charLength: number) => void
  onError?: (error: string) => void
  onBoundary?: (charIndex: number, name: string) => void
}

// Speaking state
export interface TTSState {
  isSpeaking: boolean
  isPaused: boolean
  currentText: string
  progress: number
  estimatedDuration: number
}

/**
 * Elite Neural TTS Class
 */
export class EliteNeuralTTS {
  private synthesis: SpeechSynthesis | null = null
  private currentUtterance: SpeechSynthesisUtterance | null = null
  private availableVoices: SpeechSynthesisVoice[] = []
  private selectedVoice: SpeechSynthesisVoice | null = null
  private config: TTSConfig
  private state: TTSState = {
    isSpeaking: false,
    isPaused: false,
    currentText: '',
    progress: 0,
    estimatedDuration: 0
  }

  // SSML processing for natural speech
  private ssmlEnabled = true

  // Gita-specific terms to emphasize
  private readonly wisdomTerms = [
    'dharma', 'karma', 'atman', 'equanimity', 'detachment',
    'peace', 'wisdom', 'balance', 'inner self', 'present moment',
    'consciousness', 'liberation', 'devotion', 'surrender', 'truth'
  ]

  constructor(config: Partial<TTSConfig> = {}) {
    this.config = {
      mode: 'auto',
      voicePersona: 'friendly',
      language: 'en-US',
      speechRate: 0.95,
      pitch: 1.0,
      emotionalTone: 'compassionate',
      volume: 1.0,
      ...config
    }

    this.initialize()
  }

  /**
   * Initialize TTS engine
   */
  private initialize(): void {
    if (typeof window === 'undefined') return

    this.synthesis = window.speechSynthesis

    if (!this.synthesis) {
      console.warn('Speech synthesis not supported')
      return
    }

    // Load voices
    this.loadVoices()

    // Handle voice changes (some browsers load voices async)
    if (this.synthesis.onvoiceschanged !== undefined) {
      this.synthesis.onvoiceschanged = () => this.loadVoices()
    }

    console.log('âœ… Elite Neural TTS initialized')
  }

  /**
   * Load available voices
   */
  private loadVoices(): void {
    if (!this.synthesis) return

    this.availableVoices = this.synthesis.getVoices()
    this.selectBestVoice()

    console.log(`ðŸŽ¤ Loaded ${this.availableVoices.length} voices`)
  }

  /**
   * Select best voice based on config
   */
  private selectBestVoice(): void {
    if (this.availableVoices.length === 0) return

    const lang = this.config.language
    const langVoices = this.availableVoices.filter(v =>
      v.lang.startsWith(lang.split('-')[0])
    )

    // Prefer neural/enhanced voices
    const enhancedVoices = langVoices.filter(v =>
      v.name.toLowerCase().includes('neural') ||
      v.name.toLowerCase().includes('enhanced') ||
      v.name.toLowerCase().includes('natural') ||
      v.name.toLowerCase().includes('premium')
    )

    // Voice selection based on persona
    let preferredVoices: SpeechSynthesisVoice[] = []

    switch (this.config.voicePersona) {
      case 'calm':
        // Prefer female voices for calm persona
        preferredVoices = (enhancedVoices.length > 0 ? enhancedVoices : langVoices)
          .filter(v => v.name.toLowerCase().includes('female') ||
                       v.name.toLowerCase().includes('samantha') ||
                       v.name.toLowerCase().includes('karen'))
        break
      case 'wisdom':
        // Prefer deeper/male voices for wisdom persona
        preferredVoices = (enhancedVoices.length > 0 ? enhancedVoices : langVoices)
          .filter(v => v.name.toLowerCase().includes('male') ||
                       v.name.toLowerCase().includes('daniel') ||
                       v.name.toLowerCase().includes('james'))
        break
      case 'friendly':
      default:
        // Prefer local/high-quality voices for friendly persona
        preferredVoices = (enhancedVoices.length > 0 ? enhancedVoices : langVoices)
          .filter(v => v.localService)
        break
    }

    // Select voice
    if (preferredVoices.length > 0) {
      this.selectedVoice = preferredVoices[0]
    } else if (langVoices.length > 0) {
      // Prefer local voices
      const localVoice = langVoices.find(v => v.localService)
      this.selectedVoice = localVoice || langVoices[0]
    } else if (this.availableVoices.length > 0) {
      this.selectedVoice = this.availableVoices[0]
    }

    if (this.selectedVoice) {
      console.log(`ðŸŽ¯ Selected voice: ${this.selectedVoice.name} (${this.selectedVoice.lang})`)
    }
  }

  /**
   * Speak text with SSML processing
   */
  async speak(text: string, callbacks?: TTSCallbacks): Promise<void> {
    if (!this.synthesis) {
      callbacks?.onError?.('Speech synthesis not available')
      return
    }

    // Cancel any existing speech
    this.cancel()

    // Process text for natural speech
    const processedText = this.ssmlEnabled
      ? this.processForNaturalSpeech(text)
      : text

    // Create utterance
    this.currentUtterance = new SpeechSynthesisUtterance(processedText)

    // Apply configuration
    if (this.selectedVoice) {
      this.currentUtterance.voice = this.selectedVoice
    }
    this.currentUtterance.lang = this.config.language
    this.currentUtterance.rate = this.getEmotionalRate()
    this.currentUtterance.pitch = this.getEmotionalPitch()
    this.currentUtterance.volume = this.config.volume

    // Update state
    this.state.currentText = text
    this.state.estimatedDuration = this.estimateDuration(text)

    // Set up event handlers
    return new Promise((resolve, reject) => {
      if (!this.currentUtterance) {
        reject(new Error('Utterance not created'))
        return
      }

      this.currentUtterance.onstart = () => {
        this.state.isSpeaking = true
        this.state.isPaused = false
        callbacks?.onStart?.()
      }

      this.currentUtterance.onend = () => {
        this.state.isSpeaking = false
        this.state.isPaused = false
        this.state.progress = 100
        callbacks?.onEnd?.()
        resolve()
      }

      this.currentUtterance.onpause = () => {
        this.state.isPaused = true
        callbacks?.onPause?.()
      }

      this.currentUtterance.onresume = () => {
        this.state.isPaused = false
        callbacks?.onResume?.()
      }

      this.currentUtterance.onerror = (event) => {
        this.state.isSpeaking = false
        this.state.isPaused = false

        // Handle specific errors gracefully
        if (event.error === 'interrupted' || event.error === 'canceled') {
          resolve() // Normal cancellation
          return
        }

        const errorMsg = `Speech error: ${event.error}`
        callbacks?.onError?.(errorMsg)
        reject(new Error(errorMsg))
      }

      this.currentUtterance.onboundary = (event) => {
        if (event.name === 'word' || event.name === 'sentence') {
          const progress = (event.charIndex / text.length) * 100
          this.state.progress = Math.min(progress, 100)
          callbacks?.onProgress?.(event.charIndex, text.length)
          callbacks?.onBoundary?.(event.charIndex, event.name)
        }
      }

      // Start speaking
      this.synthesis!.speak(this.currentUtterance)
    })
  }

  /**
   * Process text for natural speech (enhanced SSML-like processing)
   */
  private processForNaturalSpeech(text: string): string {
    let processed = text

    // Add natural pauses at punctuation
    processed = processed
      // Sentence endings - longer pause
      .replace(/\.\s+/g, '. ... ')
      // Questions - slightly longer pause
      .replace(/\?\s+/g, '? ... ')
      // Exclamations - moderate pause
      .replace(/!\s+/g, '! .. ')
      // Colons - short pause
      .replace(/:\s+/g, ': .. ')
      // Semicolons - short pause
      .replace(/;\s+/g, '; .. ')
      // "Here's what you can do" - add emphasis pause
      .replace(/Here's what you can do/gi, "... Here's what you can do ...")
      // "First, Second, Third" - add list pauses
      .replace(/First,/g, '... First, ...')
      .replace(/Then,/g, '... Then, ...')
      .replace(/Finally,/g, '... Finally, ...')
      .replace(/Second,/g, '... Second, ...')
      .replace(/Third,/g, '... Third, ...')

    // Add emphasis to wisdom terms (by adding brief pause before)
    for (const term of this.wisdomTerms) {
      const regex = new RegExp(`\\b(${term})\\b`, 'gi')
      processed = processed.replace(regex, ' $1')
    }

    // Clean up multiple spaces and ellipses
    processed = processed
      .replace(/\s+/g, ' ')
      .replace(/\.{4,}/g, '...')
      .trim()

    return processed
  }

  /**
   * Get emotional speech rate
   */
  private getEmotionalRate(): number {
    const baseRate = this.config.speechRate

    switch (this.config.emotionalTone) {
      case 'compassionate':
        return baseRate * 0.95 // Slightly slower for warmth
      case 'encouraging':
        return baseRate * 1.0  // Normal pace for energy
      case 'meditative':
        return baseRate * 0.85 // Slower for calm
      default:
        return baseRate
    }
  }

  /**
   * Get emotional pitch adjustment
   */
  private getEmotionalPitch(): number {
    const basePitch = this.config.pitch

    switch (this.config.emotionalTone) {
      case 'compassionate':
        return basePitch * 1.02 // Slightly higher for warmth
      case 'encouraging':
        return basePitch * 1.05 // Brighter, more energetic
      case 'meditative':
        return basePitch * 0.98 // Lower, more grounding
      default:
        return basePitch
    }
  }

  /**
   * Estimate speech duration in seconds
   */
  private estimateDuration(text: string): number {
    const wordCount = text.split(/\s+/).length
    const wordsPerMinute = 150 * this.getEmotionalRate()
    const pauseTime = (text.match(/[.!?:;]/g) || []).length * 0.3

    return (wordCount / wordsPerMinute) * 60 + pauseTime
  }

  /**
   * Pause current speech
   */
  pause(): void {
    if (this.synthesis && this.state.isSpeaking) {
      this.synthesis.pause()
    }
  }

  /**
   * Resume paused speech
   */
  resume(): void {
    if (this.synthesis && this.state.isPaused) {
      this.synthesis.resume()
    }
  }

  /**
   * Cancel current speech
   */
  cancel(): void {
    if (this.synthesis) {
      this.synthesis.cancel()
      this.state.isSpeaking = false
      this.state.isPaused = false
      this.state.progress = 0
    }
  }

  /**
   * Stop speaking (alias for cancel)
   */
  stop(): void {
    this.cancel()
  }

  /**
   * Update TTS configuration
   */
  updateConfig(config: Partial<TTSConfig>): void {
    this.config = { ...this.config, ...config }

    // Reselect voice if language or persona changed
    if (config.language || config.voicePersona) {
      this.selectBestVoice()
    }
  }

  /**
   * Get current state
   */
  getState(): TTSState {
    return { ...this.state }
  }

  /**
   * Get available voices
   */
  getAvailableVoices(): VoiceOption[] {
    return this.availableVoices.map(v => ({
      name: v.name,
      lang: v.lang,
      gender: this.detectVoiceGender(v),
      quality: this.detectVoiceQuality(v),
      localService: v.localService
    }))
  }

  /**
   * Detect voice gender from name
   */
  private detectVoiceGender(voice: SpeechSynthesisVoice): 'male' | 'female' | 'neutral' {
    const name = voice.name.toLowerCase()

    const femaleNames = ['female', 'samantha', 'victoria', 'karen', 'moira', 'tessa', 'fiona', 'alex']
    const maleNames = ['male', 'daniel', 'james', 'tom', 'david', 'gordon', 'lee']

    if (femaleNames.some(n => name.includes(n))) return 'female'
    if (maleNames.some(n => name.includes(n))) return 'male'

    return 'neutral'
  }

  /**
   * Detect voice quality from name
   */
  private detectVoiceQuality(voice: SpeechSynthesisVoice): 'standard' | 'neural' | 'wavenet' {
    const name = voice.name.toLowerCase()

    if (name.includes('neural') || name.includes('wavenet')) return 'neural'
    if (name.includes('enhanced') || name.includes('premium')) return 'wavenet'

    return 'standard'
  }

  /**
   * Check if TTS is supported
   */
  isSupported(): boolean {
    return typeof window !== 'undefined' && 'speechSynthesis' in window
  }

  /**
   * Get selected voice info
   */
  getSelectedVoice(): VoiceOption | null {
    if (!this.selectedVoice) return null

    return {
      name: this.selectedVoice.name,
      lang: this.selectedVoice.lang,
      gender: this.detectVoiceGender(this.selectedVoice),
      quality: this.detectVoiceQuality(this.selectedVoice),
      localService: this.selectedVoice.localService
    }
  }

  /**
   * Speak with specific emotional tone
   */
  async speakWithEmotion(
    text: string,
    emotion: 'compassionate' | 'encouraging' | 'meditative',
    callbacks?: TTSCallbacks
  ): Promise<void> {
    const previousTone = this.config.emotionalTone
    this.config.emotionalTone = emotion

    try {
      await this.speak(text, callbacks)
    } finally {
      this.config.emotionalTone = previousTone
    }
  }

  /**
   * Speak a Gita verse with appropriate pauses
   */
  async speakVerse(
    sanskrit: string,
    english: string,
    callbacks?: TTSCallbacks
  ): Promise<void> {
    // Format verse for speaking
    const verseText = `${sanskrit} ... ... ${english}`

    // Use meditative tone for verses
    await this.speakWithEmotion(verseText, 'meditative', callbacks)
  }
}

// Export singleton instance with default config
export const eliteNeuralTTS = new EliteNeuralTTS({
  mode: 'auto',
  voicePersona: 'friendly',
  language: 'en-US',
  speechRate: 0.95,
  pitch: 1.0,
  emotionalTone: 'compassionate',
  volume: 1.0
})
