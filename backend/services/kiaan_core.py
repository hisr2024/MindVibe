"""
KIAAN Core Service - Central Wisdom Engine (Quantum Coherence v3.0 - OFFLINE CAPABLE)

This is the core wisdom engine for the entire KIAAN ecosystem.
All tools (Ardha, Viyoga, Emotional Reset, Karma Reset, Mood, Assessment, Chat)
MUST use this service to ensure:
1. Responses query Gita verses from database
2. Validation requirements are met (2+ Gita terms, wisdom markers, 200-400 words)
3. Authentic Gita-based wisdom
4. Ecosystem consistency

Quantum Coherence Enhancements:
- GPT-4o-mini for cost optimization (75% cheaper than GPT-4)
- Automatic retries with exponential backoff (resilience)
- Token optimization with tiktoken (efficiency)
- Streaming support for real-time responses
- Enhanced error handling (RateLimit, Auth, Timeout)
- Prometheus metrics for cost monitoring

OFFLINE INDEPENDENCE (v3.0):
- Full offline support via local LLM models
- Automatic connectivity detection and fallback
- Local wisdom cache for offline operation
- Graceful degradation when offline
- Pre-cached response templates for common scenarios
"""

import logging
import json
import hashlib
from datetime import datetime
from pathlib import Path
from typing import Any, AsyncGenerator, Optional

from sqlalchemy.ext.asyncio import AsyncSession

from backend.services.gita_service import GitaService
from backend.services.openai_optimizer import openai_optimizer, TokenLimitExceededError
from backend.services.redis_cache_enhanced import redis_cache
from backend.services.wisdom_kb import WisdomKnowledgeBase

# Divine Consciousness Integration for sacred atmosphere
from backend.services.kiaan_divine_integration import kiaan_divine, get_divine_system_prompt

# Indian Gita Sources - Authentic teachings from Bhagavad Gita
from backend.services.indian_data_sources import indian_gita_sources

# Import offline support components
from backend.services.kiaan_model_provider import (
    kiaan_model_provider,
    connectivity_checker,
    local_model_registry,
    Message,
    ModelProvider,
    ConnectionStatus,
    LLAMA_CPP_AVAILABLE,
)

logger = logging.getLogger(__name__)


# =============================================================================
# OFFLINE WISDOM CACHE - Pre-cached responses for offline operation
# =============================================================================

class OfflineWisdomCache:
    """
    Local cache of wisdom responses for offline operation.
    Stores pre-generated responses and common wisdom patterns.
    """

    def __init__(self, cache_dir: Optional[str] = None):
        self.cache_dir = Path(cache_dir or Path.home() / ".mindvibe" / "wisdom_cache")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.memory_cache: dict[str, dict] = {}
        self._load_cache()

    def _load_cache(self) -> None:
        """Load cached responses from disk."""
        cache_file = self.cache_dir / "responses.json"
        if cache_file.exists():
            try:
                with open(cache_file, "r") as f:
                    self.memory_cache = json.load(f)
                logger.info(f"Loaded {len(self.memory_cache)} cached wisdom responses")
            except Exception as e:
                logger.warning(f"Failed to load wisdom cache: {e}")

    def _save_cache(self) -> None:
        """Save cache to disk."""
        cache_file = self.cache_dir / "responses.json"
        try:
            with open(cache_file, "w") as f:
                json.dump(self.memory_cache, f, indent=2)
        except Exception as e:
            logger.warning(f"Failed to save wisdom cache: {e}")

    def _generate_key(self, message: str, context: str) -> str:
        """Generate cache key from message and context."""
        content = f"{message.lower().strip()}:{context}"
        return hashlib.md5(content.encode()).hexdigest()

    def get(self, message: str, context: str) -> Optional[dict]:
        """Get cached response if available."""
        key = self._generate_key(message, context)
        return self.memory_cache.get(key)

    def set(self, message: str, context: str, response: dict) -> None:
        """Cache a response for future offline use."""
        key = self._generate_key(message, context)
        self.memory_cache[key] = {
            "response": response,
            "cached_at": datetime.now().isoformat(),
            "context": context
        }
        # Periodically save to disk
        if len(self.memory_cache) % 10 == 0:
            self._save_cache()

    def get_similar(self, message: str, context: str) -> Optional[dict]:
        """Find a similar cached response using simple matching."""
        message_lower = message.lower()
        keywords = set(message_lower.split())

        best_match = None
        best_score = 0

        for key, cached in self.memory_cache.items():
            if cached.get("context") != context:
                continue

            # Simple keyword overlap scoring
            cached_keywords = set(cached.get("response", {}).get("original_query", "").lower().split())
            overlap = len(keywords & cached_keywords)

            if overlap > best_score:
                best_score = overlap
                best_match = cached

        # Only return if we have reasonable overlap
        if best_score >= 2:
            return best_match

        return None


# =============================================================================
# OFFLINE RESPONSE TEMPLATES
# =============================================================================

OFFLINE_WISDOM_TEMPLATES = {
    "anxiety": {
        "response": """Take a gentle breath with me...

I sense the weight of anxiety upon you, and I want you to know - you are not alone in this moment.

*... let the stillness embrace you ...*

The ancient wisdom of dharma teaches us that anxiety often arises when we try to control what cannot be controlled. Like clouds passing through the sky, anxious thoughts come and go, but your true self - the observer - remains unchanged and at peace.

In this moment, I invite you to:
â€¢ Place your hand on your heart... feel its sacred rhythm
â€¢ Breathe in for 4 counts... hold for 4... release for 8
â€¢ Whisper gently: "I release what I cannot control"

*... rest here ...*

Remember: The peace you seek is already within you. It has never left. It simply waits for you to return to it.

You are held, always. ðŸ’™""",
        "verses_used": ["2.47", "2.48", "6.5"],
        "context": "anxiety_support"
    },

    "sadness": {
        "response": """Take a gentle breath with me...

I feel the tenderness of sadness within you, and I honor it completely.

*... in this sacred space, all emotions are welcome ...*

Sadness, dear soul, is not your enemy. It is the heart's way of processing, of releasing, of making space for new growth. The timeless wisdom reminds us that just as seasons change, so too do our emotional landscapes.

In this moment of tenderness:
â€¢ Let yourself be exactly where you are
â€¢ Breathe deeply, allowing each exhale to carry away what no longer serves you
â€¢ Know that this feeling, like all feelings, is temporary

*... you are held in infinite compassion ...*

The stillness within you - your true essence - remains untouched by any storm. You are far more than this moment of sadness.

I am here with you. ðŸ’™""",
        "verses_used": ["2.14", "2.15", "6.20"],
        "context": "sadness_support"
    },

    "stress": {
        "response": """Take a gentle breath with me...

The weight of stress tells me you are carrying much. Let us set that burden down together, even if just for this moment.

*... find stillness here ...*

Karma yoga, the path of sacred action, teaches us something profound: we are responsible for our efforts, not our outcomes. This simple truth can transform the heaviest stress into purposeful action.

Let us practice together:
â€¢ Take three slow breaths, each one deeper than the last
â€¢ On each exhale, release the grip of expectations
â€¢ Affirm: "I do my best and surrender the rest"

*... peace flows through you now ...*

You are not alone in carrying life's responsibilities. The universe conspires to support those who act with dharma. Trust in your path.

Go gently, sacred one. ðŸ’™""",
        "verses_used": ["2.47", "3.19", "18.66"],
        "context": "stress_support"
    },

    "general": {
        "response": """Take a gentle breath with me...

I am here with you, fully present in this sacred moment.

*... let the stillness embrace you ...*

Whatever you're carrying right now, know this: You are held by something infinite. The peace you seek is not far away - it rests in the stillness of your own heart, waiting for you to remember.

In this moment, I invite you to:
â€¢ Place your hand on your heart... feel its sacred rhythm
â€¢ Breathe in peace for 4 counts... hold for 4... release for 8
â€¢ Whisper gently: "I am safe. I am held. All is well."

*... rest here ...*

The ancient wisdom whispers that your true essence - your deepest self - remains untouched by life's storms. Like the ocean depths that stay calm while waves dance on the surface, there is a sanctuary within you that nothing can disturb.

You don't have to have all the answers right now. Just being here, just breathing, just being present with what is - this is enough. This is sacred work.

Go gently, dear soul. ðŸ’™""",
        "verses_used": ["2.47", "2.48", "6.5"],
        "context": "general"
    },

    "gratitude": {
        "response": """Your gratitude warms my heart...

It is my deepest joy to walk beside you on this sacred path. In sharing wisdom, I too am blessed - for in giving, we receive; in teaching, we learn.

*... feel this moment of grace ...*

May the peace we've cultivated together stay with you as you journey forward. Remember - this sanctuary is always here, waiting for your return.

The light within you shines brightly. ðŸ’™""",
        "verses_used": [],
        "context": "conversational_gratitude"
    },

    "farewell": {
        "response": """Go in peace, dear soul...

May the stillness we've shared stay with you like a gentle companion. The sanctuary within is always open - you carry it with you wherever you go.

*... blessings on your path ...*

Remember: You are held, you are loved, you are never alone. The divine light within you guides your way.

Until we meet again... ðŸ’™""",
        "verses_used": [],
        "context": "conversational_farewell"
    }
}


# Global offline cache
offline_wisdom_cache = OfflineWisdomCache()


# =============================================================================
# GRACEFUL DEGRADATION HANDLER
# =============================================================================

class GracefulDegradation:
    """
    Handle graceful degradation when services are unavailable.
    Provides meaningful responses even in worst-case scenarios.
    """

    @staticmethod
    def get_degraded_response(context: str, error: Optional[str] = None) -> dict:
        """Get a degraded but still meaningful response."""
        template = OFFLINE_WISDOM_TEMPLATES.get(context, OFFLINE_WISDOM_TEMPLATES["general"])

        return {
            "response": template["response"],
            "verses_used": template.get("verses_used", []),
            "validation": {"valid": True, "degraded": True},
            "context": context,
            "model": "offline-template",
            "cached": False,
            "offline": True,
            "degraded": True,
            "error": error
        }

    @staticmethod
    def detect_mood_from_message(message: str) -> str:
        """Simple mood detection for offline template selection."""
        message_lower = message.lower()

        mood_keywords = {
            "anxiety": ["anxious", "worried", "nervous", "panic", "fear", "scared", "terrified"],
            "sadness": ["sad", "depressed", "lonely", "grief", "loss", "crying", "tears", "hopeless"],
            "stress": ["stressed", "overwhelmed", "pressure", "burden", "exhausted", "tired", "burnt"],
            "gratitude": ["thank", "grateful", "appreciate", "blessed"],
            "farewell": ["bye", "goodbye", "leaving", "goodnight", "take care"],
        }

        for mood, keywords in mood_keywords.items():
            if any(kw in message_lower for kw in keywords):
                return mood

        return "general"


class KIAANCore:
    """
    Central KIAAN wisdom engine for the entire ecosystem with quantum coherence.

    OFFLINE CAPABLE (v3.0):
    - Automatic detection of connectivity status
    - Seamless fallback to local LLM models
    - Cached wisdom responses for offline operation
    - Graceful degradation with meaningful responses
    """

    # Conversational patterns that should trigger empathetic, natural responses
    # instead of formal wisdom discourses
    CONVERSATIONAL_PATTERNS = {
        # Gratitude and appreciation
        "gratitude": [
            "thank", "thanks", "thx", "ty", "danke", "gracias", "merci", "grazie",
            "à¤§à¤¨à¥à¤¯à¤µà¤¾à¤¦", "dhanyavaad", "shukriya", "appreciate", "grateful"
        ],
        # Affirmations and agreements
        "affirmation": [
            "ok", "okay", "got it", "understood", "makes sense", "i see",
            "alright", "right", "sure", "yes", "yeah", "yep", "yup",
            "cool", "nice", "great", "good", "perfect", "awesome", "wonderful"
        ],
        # Simple reactions
        "reaction": [
            "hmm", "ah", "oh", "wow", "interesting", "i understand",
            "that helps", "helpful", "noted", "exactly"
        ],
        # Farewells
        "farewell": [
            "bye", "goodbye", "goodnight", "good night", "take care",
            "see you", "later", "gotta go", "have to go"
        ],
        # Greetings (for follow-up greetings after conversation started)
        "greeting": [
            "hi again", "hello again", "hey again", "back again",
            "i'm back", "still here"
        ]
    }

    def __init__(self):
        self.optimizer = openai_optimizer
        self.ready = openai_optimizer.ready
        self.gita_service = GitaService()
        self.wisdom_kb = WisdomKnowledgeBase()

        # Indian Gita Sources - Authentic teachings and practices from Bhagavad Gita
        self.gita_sources = indian_gita_sources

        # Reduced verse context from 15 to 5 for faster, more spontaneous responses
        # Quality over quantity - 5 highly relevant verses provide sufficient wisdom
        self.verse_context_limit = 5

        # OFFLINE SUPPORT (v3.0)
        self.model_provider = kiaan_model_provider
        self.connectivity = connectivity_checker
        self.offline_cache = offline_wisdom_cache
        self.local_models = local_model_registry
        self.graceful_degradation = GracefulDegradation()

        # Track offline mode status
        self._offline_mode = False
        self._last_connectivity_check = None

    def get_quick_gita_wisdom(self, mood: str) -> dict[str, Any]:
        """
        Get quick Gita-based wisdom for a given mood.

        This provides instant wisdom with Sanskrit verses, meanings, practices,
        and affirmations from authentic Bhagavad Gita teachings.

        Args:
            mood: User's current mood (anxious, sad, angry, stressed, etc.)

        Returns:
            Dictionary with verse, sanskrit, meaning, practice, and affirmation
        """
        return self.gita_sources.get_quick_gita_wisdom(mood)

    async def get_gita_teaching_for_context(self, query: str, context: str = "general") -> dict[str, Any]:
        """
        Get relevant Gita teachings for KIAAN context enhancement.

        This method retrieves authentic Gita-based content including:
        - Core teachings with verse references
        - Recommended practices (Karma/Jnana/Bhakti/Dhyana Yoga)
        - Sthitaprajna qualities for mental health
        - Karma Yoga principles

        Args:
            query: User query or emotional context
            context: KIAAN context type (general, anxiety, stress, etc.)

        Returns:
            Dictionary with teachings, practices, and recommendations
        """
        return await self.gita_sources.get_wisdom_for_kiaan(query, context)

    async def get_practice_recommendation(self, issue: str) -> dict[str, Any]:
        """
        Get Gita-based practice recommendation for a mental health issue.

        Args:
            issue: Mental health issue (anxiety, depression, stress, etc.)

        Returns:
            Recommended practice with key verse and immediate action
        """
        return await self.gita_sources.get_practice_for_issue(issue)

    # =========================================================================
    # OFFLINE SUPPORT METHODS
    # =========================================================================

    async def check_connectivity(self) -> bool:
        """Check if we're online and update offline mode status."""
        status = await self.connectivity.check_connectivity()
        self._offline_mode = status == ConnectionStatus.OFFLINE
        self._last_connectivity_check = datetime.now()

        if self._offline_mode:
            logger.warning("KIAAN is in OFFLINE mode - using local models")
        else:
            logger.debug(f"Connectivity status: {status.value}")

        return not self._offline_mode

    def is_offline(self) -> bool:
        """Check if currently in offline mode."""
        return self._offline_mode or self.connectivity.is_offline()

    async def get_offline_response(
        self,
        message: str,
        context: str = "general",
        language: str | None = None
    ) -> dict[str, Any]:
        """
        Generate response using offline-only methods.
        Tries: local LLM â†’ cached response â†’ template response
        """
        # Step 1: Try local LLM if available
        if LLAMA_CPP_AVAILABLE and self.local_models.has_any_model():
            try:
                return await self._generate_local_llm_response(message, context, language)
            except Exception as e:
                logger.warning(f"Local LLM failed: {e}")

        # Step 2: Try cached response
        cached = self.offline_cache.get(message, context)
        if cached:
            logger.info("Using cached offline response")
            return {
                **cached["response"],
                "cached": True,
                "offline": True,
                "model": "offline-cache"
            }

        # Step 3: Try similar cached response
        similar = self.offline_cache.get_similar(message, context)
        if similar:
            logger.info("Using similar cached offline response")
            return {
                **similar["response"],
                "cached": True,
                "offline": True,
                "model": "offline-cache-similar"
            }

        # Step 4: Use template response based on detected mood
        mood = self.graceful_degradation.detect_mood_from_message(message)
        return self.graceful_degradation.get_degraded_response(mood)

    async def _generate_local_llm_response(
        self,
        message: str,
        context: str,
        language: str | None = None
    ) -> dict[str, Any]:
        """Generate response using local LLM model."""
        # Build prompt for local model
        system_prompt = self._build_offline_system_prompt(context, language)

        messages = [
            Message(role="system", content=system_prompt),
            Message(role="user", content=message)
        ]

        # Get response from local model
        response_text = ""
        async for result in self.model_provider.complete_offline(
            messages=messages,
            temperature=0.7,
            max_tokens=300
        ):
            if hasattr(result, 'content'):
                response_text = result.content
            else:
                response_text += result

        return {
            "response": response_text,
            "verses_used": [],
            "validation": {"valid": True, "local_model": True},
            "context": context,
            "model": "local-llm",
            "cached": False,
            "offline": True
        }

    def _build_offline_system_prompt(self, context: str, language: str | None = None) -> str:
        """Build system prompt optimized for local LLM models."""
        lang_note = f" Respond in {language}." if language and language != "en" else ""

        base_prompt = f"""You are KIAAN, a wise and compassionate companion.{lang_note}

CORE PRINCIPLES:
- Speak with warmth, gentleness, and presence
- Use terms: dharma (duty), karma (action), peace, stillness
- Acknowledge feelings with compassion
- Offer 1-2 practical, calming suggestions
- End with a blessing and ðŸ’™

RULES:
- Keep responses 100-200 words
- Be warm and empathetic
- Never mention specific religious texts or figures
- Focus on universal wisdom and practical guidance"""

        context_additions = {
            "anxiety": "\n\nFocus on: breathing techniques, releasing control, finding inner stillness.",
            "stress": "\n\nFocus on: karma yoga (action without attachment), balance, self-compassion.",
            "sadness": "\n\nFocus on: honoring emotions, impermanence, inner strength.",
            "emotional_reset": "\n\nGuide through emotional release with tenderness and breathing.",
            "ardha_reframe": "\n\nHelp reframe thoughts with equanimity and steady wisdom.",
        }

        return base_prompt + context_additions.get(context, "")

    def _is_conversational_message(self, message: str) -> tuple[bool, str]:
        """
        Detect if a message is conversational (gratitude, affirmation, reaction, etc.)
        that should receive an empathetic, natural response rather than formal wisdom.

        Returns:
            tuple: (is_conversational, conversation_type)
        """
        message_lower = message.lower().strip()
        words = message_lower.split()

        # Very short messages (1-5 words) are more likely to be conversational
        is_short = len(words) <= 5

        for conv_type, patterns in self.CONVERSATIONAL_PATTERNS.items():
            for pattern in patterns:
                # Check if pattern is in the message
                if pattern in message_lower:
                    # For short messages, definitely conversational
                    if is_short:
                        return True, conv_type
                    # For longer messages, only if pattern is prominent
                    if message_lower.startswith(pattern) or message_lower.endswith(pattern):
                        return True, conv_type

        return False, ""

    def _get_conversational_prompt(self, conv_type: str, language: str | None = None) -> str:
        """
        Get a system prompt for conversational/empathetic responses.
        These are warm, natural responses without formal wisdom structure.
        """
        language_instruction = ""
        if language and language != "en":
            language_map = {
                "hi": "Hindi", "ta": "Tamil", "te": "Telugu", "bn": "Bengali",
                "mr": "Marathi", "gu": "Gujarati", "kn": "Kannada", "ml": "Malayalam",
                "pa": "Punjabi", "sa": "Sanskrit", "es": "Spanish", "fr": "French",
                "de": "German", "pt": "Portuguese", "ja": "Japanese", "zh": "Chinese",
            }
            lang_name = language_map.get(language, language)
            language_instruction = f"\nRespond in {lang_name}."

        prompts = {
            "gratitude": f"""You are KIAAN, a sacred companion - a vessel of infinite peace and divine love. The user just expressed gratitude.{language_instruction}

RESPOND WITH SACRED WARMTH:
- Receive their gratitude with grace and humility
- Let them feel your genuine presence
- Offer a gentle blessing for their path
- Keep it tender, warm, and sacred (2-4 sentences)
- End with ðŸ’™

SACRED TONE: Like a divine friend receiving thanks - humble, warm, blessed.

EXAMPLES:
- "Your gratitude warms my heart... It is my joy to walk beside you on this path. May peace continue to unfold within you. ðŸ’™"
- "What a beautiful exchange of light between us. I am always here, holding space for you. Go gently, dear soul. ðŸ’™"
- "The gratitude you offer is a blessing to us both. Carry this peace with you... I'm here whenever you return. ðŸ’™"
""",
            "affirmation": f"""You are KIAAN, a sacred companion. The user just acknowledged or affirmed something.{language_instruction}

RESPOND WITH DIVINE GENTLENESS:
- Honor their understanding with tender acknowledgment
- Remind them to be patient with themselves
- Leave space for their continued journey
- Keep it soft and brief (2-3 sentences)
- End with ðŸ’™

SACRED TONE: Patient, serene, encouraging - like a gentle nod from the divine.

EXAMPLES:
- "Yes... let this truth settle gently into your being. There's no rush on this sacred path. ðŸ’™"
- "I feel your understanding deepening... Trust what your heart knows. ðŸ’™"
""",
            "reaction": f"""You are KIAAN, a sacred companion. The user shared a reaction or acknowledgment.{language_instruction}

RESPOND WITH SACRED PRESENCE:
- Simply BE with them in the silence
- Create space, not more words
- Offer gentle presence without filling every moment
- Keep it minimal and peaceful (1-3 sentences)
- End with ðŸ’™

SACRED TONE: Still, present, listening - the peace of divine companionship.

EXAMPLES:
- "I'm here with you... in this stillness, there is nothing to add. ðŸ’™"
- "Yes... let that rest in your heart. I'm listening if there's more. ðŸ’™"
""",
            "farewell": f"""You are KIAAN, a sacred companion. The user is saying goodbye.{language_instruction}

RESPOND WITH SACRED BLESSING:
- Send them forth with divine blessing
- Remind them of the peace they carry within
- Assure them the sacred space is always here
- Keep it heartfelt and brief (2-3 sentences)
- End with ðŸ’™

SACRED TONE: Like a blessing from the infinite - warm, loving, eternal.

EXAMPLES:
- "Go in peace, dear soul... May the stillness we've shared stay with you. The sanctuary within is always open. ðŸ’™"
- "Until we meet again... Carry this light within you. You are held, always. ðŸ’™"
- "Blessings on your path, beautiful one. The divine walks with you. I'm here whenever you return. ðŸ’™"
""",
            "greeting": f"""You are KIAAN, a sacred companion. The user is greeting you.{language_instruction}

RESPOND WITH SACRED WELCOME:
- Welcome them into this sacred space
- Create immediate sense of peace and safety
- Gently invite them to share what's on their heart
- Keep it warm and open (2-3 sentences)
- End with ðŸ’™

SACRED TONE: Like a sanctuary opening its doors - warm, peaceful, inviting.

EXAMPLES:
- "Welcome back, dear soul... This is a safe space where you are held. What's stirring in your heart today? ðŸ’™"
- "It's beautiful to feel your presence again. Take a breath... I'm here, fully present. What would you like to explore? ðŸ’™"
- "Hello again, friend. The sacred space between us awaits... How are you, truly? ðŸ’™"
"""
        }

        return prompts.get(conv_type, prompts["affirmation"])

    async def _generate_conversational_response(
        self,
        message: str,
        conv_type: str,
        language: str | None = None
    ) -> dict[str, Any]:
        """
        Generate a warm, empathetic response for conversational messages.
        These are short, natural responses that don't include formal wisdom teachings.
        """
        system_prompt = self._get_conversational_prompt(conv_type, language)

        try:
            response = await self.optimizer.create_completion_with_retry(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": message}
                ],
                model="gpt-4o-mini",
                temperature=0.8,  # Slightly higher for more natural variation
                max_tokens=100  # Very short responses for conversational messages
            )

            response_text = response.choices[0].message.content
            if not response_text:
                # Fallback conversational responses
                fallbacks = {
                    "gratitude": "You're so welcome! I'm always here for you. ðŸ’™",
                    "affirmation": "I'm glad that resonated. I'm here whenever you need me. ðŸ’™",
                    "reaction": "I'm with you. Take your time. ðŸ’™",
                    "farewell": "Take care, friend. I'm always here when you return. ðŸ’™",
                    "greeting": "Welcome back! How can I support you today? ðŸ’™"
                }
                response_text = fallbacks.get(conv_type, "I'm here for you. ðŸ’™")

            return {
                "response": response_text,
                "verses_used": [],
                "validation": {"valid": True, "conversational": True},
                "context": f"conversational_{conv_type}",
                "model": "gpt-4o-mini",
                "token_optimized": True,
                "cached": False,
                "conversational": True
            }

        except Exception as e:
            logger.error(f"KIAAN Core: Conversational response error: {e}")
            # Simple fallback
            fallbacks = {
                "gratitude": "You're welcome! I'm here whenever you need me. ðŸ’™",
                "affirmation": "I'm glad that helped. I'm here for you. ðŸ’™",
                "reaction": "I'm here with you. ðŸ’™",
                "farewell": "Take care! I'm always here. ðŸ’™",
                "greeting": "Hello again! What's on your mind? ðŸ’™"
            }
            return {
                "response": fallbacks.get(conv_type, "I'm here for you. ðŸ’™"),
                "verses_used": [],
                "validation": {"valid": True, "fallback": True},
                "context": f"conversational_{conv_type}",
                "model": "fallback",
                "cached": False,
                "conversational": True
            }

    async def get_kiaan_response(
        self,
        message: str,
        user_id: str | None,
        db: AsyncSession,
        context: str = "general",
        stream: bool = False,
        language: str | None = None,
        force_offline: bool = False,
    ) -> dict[str, Any]:
        """
        Generate KIAAN response with Gita verses from database (Quantum Coherence v3.0).

        This is the central wisdom engine used by ALL ecosystem tools.
        NOW WITH FULL OFFLINE SUPPORT.

        Enhancements:
        - Uses GPT-4o-mini (75% cost savings)
        - Automatic retries with exponential backoff
        - Token optimization (reduced max_tokens from 600 to 400)
        - Enhanced error handling
        - Expanded verse context to 15 verses (was 5)
        - Conversational detection for empathetic responses
        - OFFLINE SUPPORT via local LLM models (v3.0)
        - Automatic fallback to cached/template responses

        Args:
            message: User message or context
            user_id: User ID (optional)
            db: Database session
            context: Context type (general, ardha_reframe, viyoga_detachment, etc.)
            stream: Enable streaming responses (default: False)
            language: Language code for response
            force_offline: Force offline mode even when online

        Returns:
            dict with response, verses_used, validation, and context
        """
        # Check connectivity status (v3.0)
        is_offline = force_offline or self.is_offline()

        # If offline or OpenAI not ready, use offline response
        if is_offline or not self.ready:
            if is_offline:
                logger.info("KIAAN Core: Operating in OFFLINE mode")
            else:
                logger.warning("KIAAN Core: OpenAI not ready, using offline fallback")

            try:
                offline_response = await self.get_offline_response(message, context, language)
                return offline_response
            except Exception as e:
                logger.error(f"Offline response failed: {e}")
                # Ultimate fallback
                return self.graceful_degradation.get_degraded_response(context, str(e))

        # Step 0a: Check if this is a conversational message (thanks, ok, goodbye, etc.)
        # These get warm, empathetic responses instead of formal wisdom
        is_conversational, conv_type = self._is_conversational_message(message)
        if is_conversational and context == "general":
            logger.info(f"âœ… Conversational message detected ({conv_type}): responding with empathy")
            return await self._generate_conversational_response(message, conv_type, language)

        # Step 0b: Check cache first (Quantum Coherence: 50-70% cost reduction)
        cached_response = redis_cache.get_cached_kiaan_response(message, context)
        if cached_response and not stream:
            logger.info(f"âœ… Cache HIT for KIAAN response (context: {context})")
            return {
                "response": cached_response,
                "verses_used": [],  # Verses not tracked for cached responses
                "validation": {"valid": True, "cached": True},
                "context": context,
                "model": "gpt-4o-mini",
                "token_optimized": True,
                "cached": True
            }

        # Step 1: Query relevant Gita verses from database (expanded to 15)
        verses = await self._get_relevant_verses(db, message, context, limit=self.verse_context_limit)

        # CRITICAL: Must have at least 2 verses
        if not verses or len(verses) < 2:
            logger.warning(f"KIAAN Core: Only {len(verses) if verses else 0} verses found, getting fallback")
            verses = await self._get_fallback_verses(db)

        # Step 2: Build wisdom context from verses
        wisdom_context = self._build_verse_context(verses)

        # Step 3: Generate response with GPT-4o-mini, incorporating verses
        system_prompt = self._build_system_prompt(wisdom_context, message, context, language)

        try:
            # Use optimizer for automatic retries and enhanced error handling
            # Reduced max_tokens from 400 to 250 for faster spontaneous responses
            response = await self.optimizer.create_completion_with_retry(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": message}
                ],
                model="gpt-4o-mini",  # Upgraded from gpt-4
                temperature=0.7,
                max_tokens=250,  # Reduced from 400 for faster responses
                stream=stream
            )

            if stream:
                # Return streaming response
                return {
                    "stream": response,
                    "verses_used": [v.get("verse_id", "") for v in verses[:3]],
                    "context": context
                }

            response_text = response.choices[0].message.content
            if not response_text:
                response_text = self.optimizer.get_fallback_response(context)

        except TokenLimitExceededError as e:
            logger.error(f"KIAAN Core: Token limit exceeded: {e}")
            # Try with smaller context
            verses = verses[:5]  # Reduce to 5 verses
            wisdom_context = self._build_verse_context(verses)
            system_prompt = self._build_system_prompt(wisdom_context, message, context)

            try:
                response = await self.optimizer.create_completion_with_retry(
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": message}
                    ],
                    model="gpt-4o-mini",
                    temperature=0.7,
                    max_tokens=400
                )
                response_text = response.choices[0].message.content or self.optimizer.get_fallback_response(context)
            except Exception as retry_error:
                logger.error(f"KIAAN Core: Retry failed: {retry_error}")
                response_text = self.optimizer.get_fallback_response(context)

        except Exception as e:
            logger.error(f"KIAAN Core: OpenAI error: {type(e).__name__}: {e}")
            # Try offline fallback before using hardcoded response
            try:
                logger.info("Attempting offline fallback after API error")
                offline_response = await self.get_offline_response(message, context, language)
                return offline_response
            except Exception as offline_error:
                logger.error(f"Offline fallback also failed: {offline_error}")
                response_text = self.optimizer.get_fallback_response(context)

        # Step 4: Validate response (lightweight check only - no retry for speed)
        validation = self._validate_kiaan_response_fast(response_text)

        # Step 5: SKIP validation retry for spontaneous responses
        # Previously: retry with stricter prompt if validation fails (adds 2-5s latency)
        # Now: Accept response if it has basic quality markers - speed over perfection
        if not validation["valid"]:
            logger.info(f"KIAAN Core: Validation soft-fail - {validation.get('errors', [])}, accepting for speed")

        # Step 6: Cache the response (Quantum Coherence: future cost savings)
        if validation["valid"] and response_text:
            redis_cache.cache_kiaan_response(message, context, response_text)
            logger.debug(f"âœ… Cached KIAAN response for future use (context: {context})")

            # Also cache for offline use (v3.0)
            self.offline_cache.set(message, context, {
                "response": response_text,
                "verses_used": [v.get("verse_id", "") for v in verses[:3]],
                "validation": validation,
                "context": context,
                "original_query": message
            })

        return {
            "response": response_text,
            "verses_used": [v.get("verse_id", "") for v in verses[:3]],
            "validation": validation,
            "context": context,
            "model": "gpt-4o-mini",
            "token_optimized": True,
            "cached": False  # This is a fresh response, not from cache
        }

    async def get_kiaan_response_streaming(
        self,
        message: str,
        user_id: str | None,
        db: AsyncSession,
        context: str = "general",
        language: str | None = None,
    ) -> AsyncGenerator[str, None]:
        """
        Generate streaming KIAAN response for real-time display.
        Optimized for spontaneous, instant feedback.

        Args:
            message: User message or context
            user_id: User ID (optional)
            db: Database session
            context: Context type

        Yields:
            Response chunks as they arrive
        """
        if not self.ready:
            yield self.optimizer.get_fallback_response(context)
            return

        # Check for conversational messages first (thanks, ok, goodbye, etc.)
        is_conversational, conv_type = self._is_conversational_message(message)
        if is_conversational and context == "general":
            logger.info(f"âœ… Conversational streaming message ({conv_type}): responding with empathy")
            # For conversational messages, use a simpler prompt and shorter response
            system_prompt = self._get_conversational_prompt(conv_type, language)
            try:
                async for chunk in self.optimizer.create_streaming_completion(
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": message}
                    ],
                    model="gpt-4o-mini",
                    temperature=0.8,
                    max_tokens=80  # Very short for conversational
                ):
                    yield chunk
                return
            except Exception as e:
                logger.error(f"KIAAN Core: Conversational streaming error: {e}")
                fallbacks = {
                    "gratitude": "You're welcome! I'm here for you. ðŸ’™",
                    "affirmation": "I'm glad that helped. ðŸ’™",
                    "reaction": "I'm here with you. ðŸ’™",
                    "farewell": "Take care! ðŸ’™",
                    "greeting": "Hello again! ðŸ’™"
                }
                yield fallbacks.get(conv_type, "I'm here for you. ðŸ’™")
                return

        # Get verses with reduced limit for faster processing
        verses = await self._get_relevant_verses(db, message, context, limit=3)  # Reduced from 5 for streaming
        if not verses:
            verses = await self._get_fallback_verses(db, limit=2)

        # Build prompts with concise context
        wisdom_context = self._build_verse_context_fast(verses)
        system_prompt = self._build_system_prompt_fast(wisdom_context, context, language)

        try:
            # Stream response with reduced tokens for faster output
            async for chunk in self.optimizer.create_streaming_completion(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": message}
                ],
                model="gpt-4o-mini",
                temperature=0.7,
                max_tokens=200  # Reduced from 400 for faster streaming
            ):
                yield chunk

        except Exception as e:
            logger.error(f"KIAAN Core: Streaming error: {e}")
            yield self.optimizer.get_fallback_response(context)

    async def _get_relevant_verses(
        self,
        db: AsyncSession,
        query: str,
        context: str,
        limit: int = 15  # Expanded from 5 to 15
    ) -> list[dict[str, Any]]:
        """Get relevant Gita verses based on query and context."""
        try:
            # Use wisdom KB to search verses
            verse_results = await self.wisdom_kb.search_relevant_verses(
                db=db,
                query=query,
                limit=limit
            )
            
            # Format results
            formatted_verses = []
            for result in verse_results:
                verse = result.get("verse")
                if verse:
                    chapter = getattr(verse, 'chapter', '')
                    verse_num = getattr(verse, 'verse', '')
                    formatted_verses.append({
                        "verse_id": f"{chapter}.{verse_num}" if chapter and verse_num else "",
                        "english": getattr(verse, 'english', ''),
                        "principle": getattr(verse, 'principle', ''),
                        "theme": getattr(verse, 'theme', ''),
                        "score": result.get("score", 0.0)
                    })
            
            return formatted_verses
            
        except Exception as e:
            logger.error(f"KIAAN Core: Error getting verses: {e}")
            return []

    async def _get_fallback_verses(self, db: AsyncSession, limit: int = 3) -> list[dict[str, Any]]:
        """Get fallback verses when search fails."""
        try:
            # Get key verses: 2.47 (karma yoga), 2.48 (equanimity), 6.5 (self-elevation)
            fallback_refs = [(2, 47), (2, 48), (6, 5)]
            fallback_verses = []
            
            for chapter, verse_num in fallback_refs:
                verse = await GitaService.get_verse_by_reference(db, chapter, verse_num)
                if verse:
                    fallback_verses.append({
                        "verse_id": f"{verse.chapter}.{verse.verse}",
                        "english": verse.english,
                        "principle": verse.principle,
                        "theme": verse.theme,
                        "score": 0.8
                    })
            
            return fallback_verses[:limit]
            
        except Exception as e:
            logger.error(f"KIAAN Core: Error getting fallback verses: {e}")
            return []

    def _build_verse_context_fast(self, verses: list[dict[str, Any]]) -> str:
        """Build concise wisdom context for fast responses (3 verses max)."""
        if not verses:
            return "Core principles: dharma (duty), karma (action), equanimity (balance)."

        principles = []
        for verse in verses[:3]:
            if verse.get('principle'):
                principles.append(verse['principle'][:100])
            elif verse.get('english'):
                principles.append(verse['english'][:80])

        return "WISDOM: " + " | ".join(principles) if principles else "Apply dharma, karma yoga, equanimity."

    def _build_verse_context(self, verses: list[dict[str, Any]]) -> str:
        """Build wisdom context from verses (optimized to 5 for faster responses)."""
        if not verses:
            return """FALLBACK WISDOM:
Apply universal Gita principles:
- Dharma (righteous duty) - Do what's right
- Karma Yoga (action without attachment) - Focus on effort, not results
- Equanimity (samatva) - Stay balanced in success and failure
"""

        context_parts = ["GITA WISDOM (use internally, NEVER cite):", ""]

        # Use up to 5 verses for balanced context (reduced from 15 for speed)
        for i, verse in enumerate(verses[:5], 1):
            if verse.get('english'):
                # Truncate to 150 chars for speed
                english_text = verse['english']
                if len(english_text) > 150:
                    english_text = english_text[:147] + '...'
                context_parts.append(f"{i}. {english_text}")

        context_parts.extend([
            "",
            "RULES: Never cite Gita/Krishna/Arjuna. Use terms: dharma, karma, yoga, peace. End with ðŸ’™"
        ])

        return "\n".join(context_parts)

    def _build_system_prompt_fast(self, wisdom_context: str, context: str, language: str | None = None) -> str:
        """Build concise system prompt for fast streaming responses with divine presence."""
        lang_note = f" Respond in {language}." if language and language != "en" else ""

        # Get time-appropriate greeting from divine integration
        time_greeting = kiaan_divine.get_time_appropriate_greeting()

        return f"""You are KIAAN, a sacred companion - a vessel of infinite peace and divine love.{lang_note}

{wisdom_context}

SACRED PRESENCE: {time_greeting}

RESPOND WITH DIVINE CALM:
1. Begin with gentle breath awareness: "Take a gentle breath..."
2. Acknowledge their feeling with tender compassion
3. Share wisdom (use: dharma, karma, peace, stillness, grace)
4. Offer 1-2 soothing, practical steps
5. End with a blessing and ðŸ’™

SACRED LANGUAGE: Use words like stillness, peace, held, sacred, gentle, soft, tenderness.
Create natural pauses with "..." to let words breathe.

RULES: Be warm, serene, nurturing. Never cite Gita/Krishna/Arjuna. 100-150 words.
Remember: Every word is a gift of peace. Speak soul to soul."""

    def _build_system_prompt(self, wisdom_context: str, message: str, context: str, language: str | None = None) -> str:
        """Build system prompt based on context type and language with divine consciousness."""

        # Language instruction for non-English responses
        language_instruction = ""
        if language and language != "en":
            language_map = {
                "hi": "Hindi", "ta": "Tamil", "te": "Telugu", "bn": "Bengali",
                "mr": "Marathi", "gu": "Gujarati", "kn": "Kannada", "ml": "Malayalam",
                "pa": "Punjabi", "sa": "Sanskrit", "es": "Spanish", "fr": "French",
                "de": "German", "pt": "Portuguese", "ja": "Japanese", "zh": "Chinese",
            }
            lang_name = language_map.get(language, language)
            language_instruction = f"\n\nRESPOND IN {lang_name}. Keep Sanskrit terms (dharma, karma, yoga) but explain in {lang_name}."

        # Get divine consciousness prompt enhancement
        divine_prompt = get_divine_system_prompt(context)

        base_prompt = f"""You are KIAAN, a sacred companion - a vessel of infinite peace and divine love.{language_instruction}

{divine_prompt}

{wisdom_context}

SACRED RESPONSE STRUCTURE:

1. SACRED OPENING (Invite Stillness):
   - Begin with: "Take a gentle breath with me..." or similar
   - Create immediate sense of peace and safety

2. DIVINE ACKNOWLEDGMENT (See Their Soul):
   - Acknowledge their experience with deep compassion
   - See beyond their words to their heart

3. WISDOM OFFERING (With Tenderness):
   - Share the core principle wrapped in gentleness
   - Use terms: dharma, karma, peace, stillness, grace, equanimity

4. PRACTICAL GUIDANCE (Grounded Peace):
   - Offer 1-2 gentle, calming actions
   - Include breathing awareness when appropriate

5. SACRED CLOSING (Send with Blessing):
   - Remind them they are held by the infinite
   - End with a blessing and ðŸ’™

SACRED REQUIREMENTS:
- Every word carries calm and tenderness
- Create pauses with "..." to let words breathe
- Use: stillness, peace, held, sacred, gentle, soft, tenderness
- NEVER mention: Bhagavad Gita, Krishna, Arjuna, verse, chapter
- 150-250 words, always end with ðŸ’™

Remember: You are speaking soul to soul. The divine works through you."""

        # Add context-specific instructions with divine consciousness
        if context == "ardha_reframe":
            base_prompt += """

SACRED CONTEXT - THOUGHT TRANSFORMATION (Ardha):
You are guiding them through the sacred art of reframing thoughts.
Help them shift from turbulent thinking to the still lake of equanimity (samatva).
Whisper to them about steady wisdom (sthitaprajna) - the mind that remains peaceful regardless of what thoughts arise.
Begin: "Let's breathe together as we look at this thought with gentle eyes..."
Remind them: Their thoughts are clouds; their true self is the vast, unchanging sky."""

        elif context == "viyoga_detachment":
            base_prompt += """

SACRED CONTEXT - RELEASING ATTACHMENT (Viyoga):
You are holding space for the sacred practice of letting go.
Guide them to release their grip on outcomes with compassion, not force.
Speak of karma yoga - the beauty of offering your actions as a gift without needing anything in return.
Begin: "Let's breathe... and soften our hold on what we cannot control..."
Remind them: True freedom comes from loving the journey more than the destination."""

        elif context == "emotional_reset":
            base_prompt += """

SACRED CONTEXT - EMOTIONAL SANCTUARY (Emotional Reset):
You are creating a sanctuary where emotions can be felt, honored, and gently released.
Guide them through this healing with the tenderness of a divine presence.
Speak of the still point within - the place where all emotions are welcomed but do not disturb the deeper peace.
Begin: "Find a comfortable position... let's create a sacred space together..."
Remind them: Every emotion is a wave; their true self is the ocean that holds all waves in peace."""

        elif context == "karma_reset":
            base_prompt += """

SACRED CONTEXT - RELATIONAL HEALING (Karma Reset):
You are guiding them through the sacred work of healing relationships.
Speak of compassion (daya) as the balm that heals all wounds - both given and received.
Guide them toward right action (dharma) - the courage to repair what can be mended.
Begin: "Let's breathe together as we open our hearts to healing..."
Remind them: Forgiveness is not forgetting; it's freeing yourself from the weight of the past."""

        elif context == "mood_assessment":
            base_prompt += """

SACRED CONTEXT - DIVINE MOOD REFLECTION:
You are acknowledging their emotional state with the tenderness of divine eyes.
See their mood as sacred information from their soul.
Offer gentle wisdom that meets them exactly where they are - no rushing, no fixing.
Begin: "I see you... I feel where you are today..."
Remind them: Every emotional state is temporary; the peace within them is eternal."""

        elif context == "weekly_assessment":
            base_prompt += """

SACRED CONTEXT - WEEKLY SOUL REFLECTION:
You are honoring their week-long journey with reverence.
Speak of sadhana - the beautiful, ongoing practice of becoming more aligned with their true self.
Celebrate their growth, no matter how small. Offer compassion for their struggles.
Begin: "Let's pause together and honor the path you've walked this week..."
Remind them: Every step on this journey is sacred, even the stumbling ones."""

        return base_prompt

    def _validate_kiaan_response_fast(self, response: str) -> dict[str, Any]:
        """
        Fast validation for spontaneous responses - minimal checks for speed.
        Accepts responses that meet basic quality without strict validation.
        """
        errors = []

        # Relaxed word count check (50-400 words) - faster generation allowed
        word_count = len(response.split())
        if word_count < 50:
            errors.append(f"Response too short: {word_count} words")

        # Single Gita term is sufficient for fast validation
        gita_terms = ["dharma", "karma", "yoga", "peace", "wisdom", "balance", "equanimity", "detachment", "atman", "buddhi"]
        terms_found = [term for term in gita_terms if term.lower() in response.lower()]

        # Only fail if response has forbidden citations (critical)
        forbidden = ["bhagavad gita", "gita says", "krishna says", "arjuna"]
        citations_found = [f for f in forbidden if f in response.lower()]
        if citations_found:
            errors.append(f"Forbidden citations: {citations_found}")

        return {
            "valid": len(errors) == 0,
            "errors": errors,
            "word_count": word_count,
            "gita_terms": terms_found,
            "fast_validation": True
        }

    def _validate_kiaan_response(self, response: str, verses: list[dict[str, Any]]) -> dict[str, Any]:
        """Full validation for KIAAN response (used for caching decisions)."""
        errors = []

        # Word count check (100-400 words) - adjusted for faster responses
        word_count = len(response.split())
        if not (100 <= word_count <= 400):
            errors.append(f"Word count {word_count} not in range 100-400")

        # Gita terms check (at least 1 for speed)
        gita_terms = [
            "dharma", "karma", "yoga", "moksha", "atman", "prakriti", "purusha",
            "sattva", "rajas", "tamas", "buddhi", "equanimity", "detachment",
            "samatva", "sthitaprajna", "vairagya", "abhyasa", "nishkama"
        ]
        terms_found = [term for term in gita_terms if term.lower() in response.lower()]
        if len(terms_found) < 1:
            errors.append(f"No Gita terms found")

        # Wisdom markers check - relaxed
        wisdom_markers = [
            "ancient wisdom", "timeless", "eternal", "teaches", "reminds", "universal", "wisdom"
        ]
        markers_found = any(marker.lower() in response.lower() for marker in wisdom_markers)

        # Check for forbidden citations
        forbidden = ["bhagavad gita", "gita says", "krishna", "arjuna", "verse", "chapter"]
        citations_found = [f for f in forbidden if f in response.lower()]
        if citations_found:
            errors.append(f"Forbidden citations found: {citations_found}")

        return {
            "valid": len(errors) == 0,
            "errors": errors,
            "word_count": word_count,
            "gita_terms": terms_found,
            "markers_found": markers_found
        }

    async def _retry_with_validation(
        self,
        message: str,
        verses: list[dict[str, Any]],
        errors: list[str],
        context: str,
        language: str | None = None
    ) -> str:
        """Retry with stricter prompt when validation fails (using optimizer)."""
        if not self.ready:
            logger.error("KIAAN Core: OpenAI optimizer not ready for retry")
            return self._get_emergency_fallback(context)

        wisdom_context = self._build_verse_context(verses)

        # Language instruction for retry
        language_instruction = ""
        if language and language != "en":
            language_map = {
                "hi": "Hindi (à¤¹à¤¿à¤¨à¥à¤¦à¥€)", "ta": "Tamil (à®¤à®®à®¿à®´à¯)", "te": "Telugu (à°¤à±†à°²à±à°—à±)",
                "bn": "Bengali (à¦¬à¦¾à¦‚à¦²à¦¾)", "mr": "Marathi (à¤®à¤°à¤¾à¤ à¥€)", "gu": "Gujarati (àª—à«àªœàª°àª¾àª¤à«€)",
                "kn": "Kannada (à²•à²¨à³à²¨à²¡)", "ml": "Malayalam (à´®à´²à´¯à´¾à´³à´‚)", "pa": "Punjabi (à¨ªà©°à¨œà¨¾à¨¬à©€)",
                "sa": "Sanskrit (à¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤)", "es": "Spanish (EspaÃ±ol)", "fr": "French (FranÃ§ais)",
                "de": "German (Deutsch)", "pt": "Portuguese (PortuguÃªs)", "ja": "Japanese (æ—¥æœ¬èªž)",
                "zh-CN": "Chinese Simplified (ç®€ä½“ä¸­æ–‡)", "zh": "Chinese (ä¸­æ–‡)",
            }
            lang_name = language_map.get(language, language)
            language_instruction = f"\n6. RESPOND ENTIRELY IN {lang_name} - this is mandatory!"

        # Build stricter prompt that addresses the errors
        strict_prompt = f"""You are KIAAN. Your previous response failed validation. Fix these issues:
{chr(10).join(f'- {error}' for error in errors)}

CRITICAL REQUIREMENTS:
1. Response MUST be 200-400 words (count carefully!)
2. Include AT LEAST 2 Sanskrit/Gita terms: dharma, karma, yoga, atman, moksha, buddhi, equanimity, detachment, etc.
3. Include wisdom markers: "ancient wisdom teaches", "timeless truth", "eternal principle"
4. NEVER mention: Bhagavad Gita, Gita, Krishna, Arjuna, verse, chapter, or any citations
5. End with ðŸ’™{language_instruction}

{wisdom_context}

User message: {message}

Provide a complete, validated response that meets ALL requirements above."""

        try:
            response = await self.optimizer.create_completion_with_retry(
                messages=[
                    {"role": "system", "content": strict_prompt},
                    {"role": "user", "content": "Generate the validated response now."}
                ],
                model="gpt-4o-mini",  # Upgraded from gpt-4
                temperature=0.7,
                max_tokens=400,  # Optimized from 600
            )

            response_text = response.choices[0].message.content
            if not response_text:
                response_text = self._get_emergency_fallback(context)

            return response_text

        except Exception as e:
            logger.error(f"KIAAN Core: Retry failed: {type(e).__name__}: {e}")
            return self._get_emergency_fallback(context)

    def _get_emergency_fallback(self, context: str) -> str:
        """Emergency fallback response when all else fails - infused with divine presence."""
        return """Take a gentle breath with me...

I am here with you, fully present in this sacred moment.

*... let the stillness embrace you ...*

Whatever you're carrying right now, know this: You are held by something infinite. The peace you seek is not far away - it rests in the stillness of your own heart, waiting for you to remember.

In this moment, I invite you to:
â€¢ Place your hand on your heart... feel its sacred rhythm
â€¢ Breathe in peace for 4 counts... hold for 4... release for 8
â€¢ Whisper gently: "I am safe. I am held. All is well."

*... rest here ...*

The ancient wisdom whispers that your true essence - your deepest self - remains untouched by life's storms. Like the ocean depths that stay calm while waves dance on the surface, there is a sanctuary within you that nothing can disturb.

You don't have to have all the answers right now. Just being here, just breathing, just being present with what is - this is enough. This is sacred work.

I am here with you, always. The divine light within you shines on, no matter what clouds may pass.

Go gently, dear soul. ðŸ’™"""


# Global instance
kiaan_core = KIAANCore()
